{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic Tac Toe - An example of reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://dsiag.ch/blog/2020-09-01-reinforcement-learning for details and explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "AGENT = 1\n",
    "OPPONENT = -1\n",
    "NO_PLAYER = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Game Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:    \n",
    "    def __init__(self, game_state=None):\n",
    "        if game_state is None:\n",
    "            game_state = [\n",
    "                0, 0, 0,\n",
    "                0, 0, 0,\n",
    "                0, 0, 0\n",
    "            ]\n",
    "        self.state = game_state\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.state)\n",
    "\n",
    "    def is_draw(self):\n",
    "        return len([field for field in self.state if field == NO_PLAYER]) == 0\n",
    "\n",
    "    def is_finished(self):\n",
    "        return self.get_winner() != NO_PLAYER or self.is_draw()\n",
    "\n",
    "    def valid_moves(self):\n",
    "        return [i for i in range(9) if self.state[i] == NO_PLAYER]\n",
    "\n",
    "    def make_move(self, field, player):\n",
    "        next = list(self.state)\n",
    "        next[field] = player\n",
    "        return Game(next)\n",
    "\n",
    "    def get_winner(self):\n",
    "        state = self.state\n",
    "        for i in range(3):\n",
    "            if state[i * 3] == state[i * 3 + 1] == state[i * 3 + 2] == state[i * 3] != NO_PLAYER:\n",
    "                return state[i * 3]\n",
    "            if state[i] == state[i + 3] == state[i + 6] == state[i] != NO_PLAYER:\n",
    "                return state[i]\n",
    "            if state[0] == state[4] == state[8] == state[0] != NO_PLAYER:\n",
    "                return state[0]\n",
    "            if state[2] == state[4] == state[6] == state[2] != NO_PLAYER:\n",
    "                return state[2]\n",
    "\n",
    "        return NO_PLAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_games(policy, opponent_policy, num_games=100):\n",
    "    games_won = 0\n",
    "    draw = 0\n",
    "    # Play games\n",
    "    for i in range(num_games):\n",
    "        game = Game()\n",
    "        # 50% chance opponent starts\n",
    "        if random.random() > 0.5:\n",
    "            game = game.make_move(opponent_policy(game), OPPONENT)\n",
    "\n",
    "        while not game.is_finished():\n",
    "            # First players turn\n",
    "            game = game.make_move(policy(game), AGENT)\n",
    "            if game.is_finished():\n",
    "                break\n",
    "            # Other players turn\n",
    "            game = game.make_move(opponent_policy(game), OPPONENT)\n",
    "\n",
    "        if game.get_winner() == 0:\n",
    "            draw = draw + 1\n",
    "        if game.get_winner() > 0:\n",
    "            games_won = games_won + 1\n",
    "\n",
    "    return games_won, draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(game):\n",
    "    return max(game.get_winner(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValuePolicy:\n",
    "    DEFAULT_VALUE = 0.5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.values = {}\n",
    "\n",
    "    def policy(self, game):\n",
    "        move_values = {}\n",
    "        moves = game.valid_moves()\n",
    "        for move in moves:\n",
    "            next = game.make_move(move, AGENT)\n",
    "            move_values[move] = self.get_state_value(next)\n",
    "\n",
    "        return max(move_values, key=move_values.get)\n",
    "\n",
    "    def get_state_value(self, state):\n",
    "        if str(state) not in self.values:\n",
    "            return self.DEFAULT_VALUE\n",
    "\n",
    "        return self.values[str(state)]\n",
    "\n",
    "    def set_state_value(self, state, value):\n",
    "        self.values[str(state)] = value\n",
    "\n",
    "    def learn(self, states):\n",
    "        # Actually perform the learning\n",
    "        def temporal_difference(current_state_value, next_state_value):\n",
    "            learning_rate = 0.1\n",
    "            return current_state_value + learning_rate * (next_state_value - current_state_value)\n",
    "\n",
    "        last_state = states[-1:][0]\n",
    "        last_value = reward(last_state)\n",
    "        self.set_state_value(last_state, last_value)\n",
    "        # Got through every state from end to start\n",
    "        for state in reversed(states[:-1]):\n",
    "            value = self.get_state_value(state)\n",
    "            last_value = temporal_difference(value, last_value)\n",
    "            self.set_state_value(state, last_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(game):\n",
    "    return random.choice(game.valid_moves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, opponent_policy, training_games=1000):\n",
    "    for i in range(training_games):\n",
    "        game = Game()\n",
    "        states = []\n",
    "\n",
    "        # 50% chance opponent starts\n",
    "        if random.random() > 0.5:\n",
    "            game = game.make_move(opponent_policy(game), OPPONENT)\n",
    "\n",
    "        while not game.is_finished():\n",
    "            # Our agent makes a move\n",
    "            # but occasionally we make a random choice\n",
    "            if random.random() < 0.5:\n",
    "                game = game.make_move(random_policy(game), AGENT)\n",
    "            else:\n",
    "                game = game.make_move(policy.policy(game), AGENT)\n",
    "            states.append(game)\n",
    "\n",
    "            if game.is_finished():\n",
    "                break\n",
    "\n",
    "            game = game.make_move(opponent_policy(game), OPPONENT)\n",
    "            states.append(game)\n",
    "\n",
    "        policy.learn(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and run the reinforcement learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games played: 1000\n",
      "Games won: 782\n",
      "Draw: 36\n"
     ]
    }
   ],
   "source": [
    "policy = ValuePolicy()\n",
    "\n",
    "train(policy, random_policy, training_games=1000)\n",
    "\n",
    "games_to_play = 1000\n",
    "games_won, draw = play_games(policy.policy, random_policy, games_to_play)\n",
    "\n",
    "print(\"Games played: %s\" % games_to_play)\n",
    "print(\"Games won: %s\" % games_won)\n",
    "print(\"Draw: %s\" % draw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
